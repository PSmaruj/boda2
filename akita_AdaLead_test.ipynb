{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import boda\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"/home1/smaruj/AkitaMini-pytorch\")  # Add the directory where \"ledidi\" is located\n",
    "from model import SeqNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from akita_helper import plot_map, from_upper_triu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_225516/ipykernel_689058/2425661507.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/home1/smaruj/AkitaMini-pytorch/best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SeqNN()\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load('/home1/smaruj/AkitaMini-pytorch/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = next(model.parameters()).device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqNN(\n",
       "  (stochastic_reverse_complement): StochasticReverseComplement()\n",
       "  (stochastic_shift): StochasticShift()\n",
       "  (re_lu): ReLU()\n",
       "  (conv_block_1): ConvBlock(\n",
       "    (conv): Conv1d(4, 96, kernel_size=(11,), stride=(1,), padding=(5,), bias=False)\n",
       "    (batch_norm): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (pool): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_tower): ConvTower(\n",
       "    (conv_tower): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (2): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): ReLU()\n",
       "      (5): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (6): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): ReLU()\n",
       "      (9): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (10): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "      (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (12): ReLU()\n",
       "      (13): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (14): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "      (15): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (16): ReLU()\n",
       "      (17): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (18): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "      (19): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (20): ReLU()\n",
       "      (21): Conv1d(96, 96, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (22): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "      (23): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (residual1d_block1): ResidualDilatedBlock1D(\n",
       "    (relu1): ReLU()\n",
       "    (conv1): Conv1d(96, 48, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(48, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU()\n",
       "    (conv2): Conv1d(48, 96, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn2): BatchNorm1d(96, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       "  (conv_reduce): ConvBlockReduce(\n",
       "    (layers): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Conv1d(96, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (2): BatchNorm1d(64, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (one_to_two): OneToTwo()\n",
       "  (concat_dist): ConcatDist2D()\n",
       "  (conv2d_block): Conv2DBlock(\n",
       "    (block): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Conv2d(65, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(48, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (symmetrize_2d): Symmetrize2D()\n",
       "  (residual2d_block1): DilatedResidualBlock2D(\n",
       "    (relu): ReLU()\n",
       "    (conv1): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(24, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(48, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (symmetrize): Symmetrize2D()\n",
       "  )\n",
       "  (residual2d_block2): DilatedResidualBlock2D(\n",
       "    (relu): ReLU()\n",
       "    (conv1): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(24, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "    (bn2): BatchNorm2d(48, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (symmetrize): Symmetrize2D()\n",
       "  )\n",
       "  (residual2d_block3): DilatedResidualBlock2D(\n",
       "    (relu): ReLU()\n",
       "    (conv1): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    (bn1): BatchNorm2d(24, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), dilation=(4, 4), bias=False)\n",
       "    (bn2): BatchNorm2d(48, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (symmetrize): Symmetrize2D()\n",
       "  )\n",
       "  (residual2d_block4): DilatedResidualBlock2D(\n",
       "    (relu): ReLU()\n",
       "    (conv1): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(7, 7), dilation=(7, 7), bias=False)\n",
       "    (bn1): BatchNorm2d(24, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), dilation=(7, 7), bias=False)\n",
       "    (bn2): BatchNorm2d(48, eps=0.001, momentum=0.0735, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (symmetrize): Symmetrize2D()\n",
       "  )\n",
       "  (cropping_2d): Cropping2D()\n",
       "  (upper_tri): UpperTri()\n",
       "  (final): Final(\n",
       "    (dense): Linear(in_features=48, out_features=1, bias=True)\n",
       "  )\n",
       "  (switch_reverse_triu): SwitchReverseTriu()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode (important for inference)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SeqNN                                    [2, 1, 1953]              --\n",
       "├─StochasticReverseComplement: 1-1       [2, 4, 32768]             --\n",
       "├─StochasticShift: 1-2                   [2, 4, 32768]             --\n",
       "├─ReLU: 1-3                              [2, 4, 32768]             --\n",
       "├─ConvBlock: 1-4                         [2, 96, 4096]             --\n",
       "│    └─Conv1d: 2-1                       [2, 96, 32768]            4,224\n",
       "│    └─BatchNorm1d: 2-2                  [2, 96, 32768]            192\n",
       "│    └─MaxPool1d: 2-3                    [2, 96, 4096]             --\n",
       "├─ConvTower: 1-5                         [2, 96, 64]               --\n",
       "│    └─Sequential: 2-4                   [2, 96, 64]               --\n",
       "│    │    └─ReLU: 3-1                    [2, 96, 4096]             --\n",
       "│    │    └─Conv1d: 3-2                  [2, 96, 4096]             46,080\n",
       "│    │    └─BatchNorm1d: 3-3             [2, 96, 4096]             192\n",
       "│    │    └─MaxPool1d: 3-4               [2, 96, 2048]             --\n",
       "│    │    └─ReLU: 3-5                    [2, 96, 2048]             --\n",
       "│    │    └─Conv1d: 3-6                  [2, 96, 2048]             46,080\n",
       "│    │    └─BatchNorm1d: 3-7             [2, 96, 2048]             192\n",
       "│    │    └─MaxPool1d: 3-8               [2, 96, 1024]             --\n",
       "│    │    └─ReLU: 3-9                    [2, 96, 1024]             --\n",
       "│    │    └─Conv1d: 3-10                 [2, 96, 1024]             46,080\n",
       "│    │    └─BatchNorm1d: 3-11            [2, 96, 1024]             192\n",
       "│    │    └─MaxPool1d: 3-12              [2, 96, 512]              --\n",
       "│    │    └─ReLU: 3-13                   [2, 96, 512]              --\n",
       "│    │    └─Conv1d: 3-14                 [2, 96, 512]              46,080\n",
       "│    │    └─BatchNorm1d: 3-15            [2, 96, 512]              192\n",
       "│    │    └─MaxPool1d: 3-16              [2, 96, 256]              --\n",
       "│    │    └─ReLU: 3-17                   [2, 96, 256]              --\n",
       "│    │    └─Conv1d: 3-18                 [2, 96, 256]              46,080\n",
       "│    │    └─BatchNorm1d: 3-19            [2, 96, 256]              192\n",
       "│    │    └─MaxPool1d: 3-20              [2, 96, 128]              --\n",
       "│    │    └─ReLU: 3-21                   [2, 96, 128]              --\n",
       "│    │    └─Conv1d: 3-22                 [2, 96, 128]              46,080\n",
       "│    │    └─BatchNorm1d: 3-23            [2, 96, 128]              192\n",
       "│    │    └─MaxPool1d: 3-24              [2, 96, 64]               --\n",
       "├─ResidualDilatedBlock1D: 1-6            [2, 96, 64]               --\n",
       "│    └─ReLU: 2-5                         [2, 96, 64]               --\n",
       "│    └─Conv1d: 2-6                       [2, 48, 64]               13,824\n",
       "│    └─BatchNorm1d: 2-7                  [2, 48, 64]               96\n",
       "│    └─ReLU: 2-8                         [2, 48, 64]               --\n",
       "│    └─Conv1d: 2-9                       [2, 96, 64]               4,608\n",
       "│    └─BatchNorm1d: 2-10                 [2, 96, 64]               192\n",
       "│    └─Dropout: 2-11                     [2, 96, 64]               --\n",
       "├─ConvBlockReduce: 1-7                   [2, 64, 64]               --\n",
       "│    └─Sequential: 2-12                  [2, 64, 64]               --\n",
       "│    │    └─ReLU: 3-25                   [2, 96, 64]               --\n",
       "│    │    └─Conv1d: 3-26                 [2, 64, 64]               30,720\n",
       "│    │    └─BatchNorm1d: 3-27            [2, 64, 64]               128\n",
       "│    │    └─ReLU: 3-28                   [2, 64, 64]               --\n",
       "├─OneToTwo: 1-8                          [2, 64, 64, 64]           --\n",
       "├─ConcatDist2D: 1-9                      [2, 65, 64, 64]           --\n",
       "├─Conv2DBlock: 1-10                      [2, 48, 64, 64]           --\n",
       "│    └─Sequential: 2-13                  [2, 48, 64, 64]           --\n",
       "│    │    └─ReLU: 3-29                   [2, 65, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-30                 [2, 48, 64, 64]           28,080\n",
       "│    │    └─BatchNorm2d: 3-31            [2, 48, 64, 64]           96\n",
       "├─Symmetrize2D: 1-11                     [2, 48, 64, 64]           --\n",
       "├─DilatedResidualBlock2D: 1-12           [2, 48, 64, 64]           --\n",
       "│    └─ReLU: 2-14                        [2, 48, 64, 64]           --\n",
       "│    └─Conv2d: 2-15                      [2, 24, 64, 64]           10,368\n",
       "│    └─BatchNorm2d: 2-16                 [2, 24, 64, 64]           48\n",
       "│    └─ReLU: 2-17                        [2, 24, 64, 64]           --\n",
       "│    └─Conv2d: 2-18                      [2, 48, 64, 64]           1,152\n",
       "│    └─BatchNorm2d: 2-19                 [2, 48, 64, 64]           96\n",
       "│    └─Dropout2d: 2-20                   [2, 48, 64, 64]           --\n",
       "│    └─Symmetrize2D: 2-21                [2, 48, 64, 64]           --\n",
       "├─DilatedResidualBlock2D: 1-13           [2, 48, 64, 64]           --\n",
       "│    └─ReLU: 2-22                        [2, 48, 64, 64]           --\n",
       "│    └─Conv2d: 2-23                      [2, 24, 64, 64]           10,368\n",
       "│    └─BatchNorm2d: 2-24                 [2, 24, 64, 64]           48\n",
       "│    └─ReLU: 2-25                        [2, 24, 64, 64]           --\n",
       "│    └─Conv2d: 2-26                      [2, 48, 64, 64]           1,152\n",
       "│    └─BatchNorm2d: 2-27                 [2, 48, 64, 64]           96\n",
       "│    └─Dropout2d: 2-28                   [2, 48, 64, 64]           --\n",
       "│    └─Symmetrize2D: 2-29                [2, 48, 64, 64]           --\n",
       "├─DilatedResidualBlock2D: 1-14           [2, 48, 64, 64]           --\n",
       "│    └─ReLU: 2-30                        [2, 48, 64, 64]           --\n",
       "│    └─Conv2d: 2-31                      [2, 24, 64, 64]           10,368\n",
       "│    └─BatchNorm2d: 2-32                 [2, 24, 64, 64]           48\n",
       "│    └─ReLU: 2-33                        [2, 24, 64, 64]           --\n",
       "│    └─Conv2d: 2-34                      [2, 48, 64, 64]           1,152\n",
       "│    └─BatchNorm2d: 2-35                 [2, 48, 64, 64]           96\n",
       "│    └─Dropout2d: 2-36                   [2, 48, 64, 64]           --\n",
       "│    └─Symmetrize2D: 2-37                [2, 48, 64, 64]           --\n",
       "├─DilatedResidualBlock2D: 1-15           [2, 48, 64, 64]           --\n",
       "│    └─ReLU: 2-38                        [2, 48, 64, 64]           --\n",
       "│    └─Conv2d: 2-39                      [2, 24, 64, 64]           10,368\n",
       "│    └─BatchNorm2d: 2-40                 [2, 24, 64, 64]           48\n",
       "│    └─ReLU: 2-41                        [2, 24, 64, 64]           --\n",
       "│    └─Conv2d: 2-42                      [2, 48, 64, 64]           1,152\n",
       "│    └─BatchNorm2d: 2-43                 [2, 48, 64, 64]           96\n",
       "│    └─Dropout2d: 2-44                   [2, 48, 64, 64]           --\n",
       "│    └─Symmetrize2D: 2-45                [2, 48, 64, 64]           --\n",
       "├─Cropping2D: 1-16                       [2, 48, 64, 64]           --\n",
       "├─UpperTri: 1-17                         [2, 48, 1953]             --\n",
       "├─Final: 1-18                            [2, 1, 1953]              --\n",
       "│    └─Linear: 2-46                      [2, 1953, 1]              49\n",
       "├─SwitchReverseTriu: 1-19                [2, 1, 1953]              --\n",
       "==========================================================================================\n",
       "Total params: 406,497\n",
       "Trainable params: 406,497\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.63\n",
       "==========================================================================================\n",
       "Input size (MB): 1.05\n",
       "Forward/backward pass size (MB): 169.93\n",
       "Params size (MB): 1.63\n",
       "Estimated Total Size (MB): 172.61\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(2, 4, 32768), col_names=[\"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_225516/ipykernel_689058/413687493.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load('/home1/smaruj/AkitaMini-pytorch/test_data.pt')\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "test_data = torch.load('/home1/smaruj/AkitaMini-pytorch/test_data.pt')\n",
    "\n",
    "# Assume test_data is a tuple of (X, y)\n",
    "X_test, y_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 3\n",
    "X_batch = X_test[:num_examples]\n",
    "y_batch = y_test[:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = X_batch.to(device), y_batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to get the indices of the upper triangular part for a given matrix size\n",
    "def get_upper_triu_indices(dim, num_diags=2):\n",
    "    return np.triu_indices(dim, k=num_diags)\n",
    "\n",
    "# The matrix size you are working with\n",
    "dim = 64\n",
    "# The starting and ending indices for the chunk (0:21, 21:38)\n",
    "start_row, end_row = 0, 20\n",
    "start_col, end_col = 20, 36\n",
    "\n",
    "# Get the full upper triangular indices for the 64x64 matrix\n",
    "full_indices = get_upper_triu_indices(dim)\n",
    "\n",
    "# Now create a mask to extract the relevant slice of the matrix\n",
    "mask = ((full_indices[0] >= start_row) & (full_indices[0] < end_row) &\n",
    "        (full_indices[1] >= start_col) & (full_indices[1] < end_col))\n",
    "\n",
    "# Extract the corresponding indices from the full 64x64 vector\n",
    "sub_indices_in_full_vector = np.where(mask)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_slices_fixed(indices):\n",
    "    slices = []\n",
    "    start = indices[0]\n",
    "    \n",
    "    for i in range(1, len(indices)):\n",
    "        if indices[i] != indices[i-1] + 1:  # New contiguous block detected\n",
    "            slices.append(slice(start, indices[i-1] + 1))\n",
    "            start = indices[i]\n",
    "    \n",
    "    # Append the last slice\n",
    "    slices.append(slice(start, indices[-1] + 1))\n",
    "    \n",
    "    # Compute the max slice length\n",
    "    max_length = max(s.stop - s.start for s in slices)\n",
    "\n",
    "    # Expand shorter slices to match max_length\n",
    "    slices_fixed = []\n",
    "    for s in slices:\n",
    "        length = s.stop - s.start\n",
    "        if length < max_length:\n",
    "            new_stop = s.start + max_length  # Expand\n",
    "            slices_fixed.append(slice(s.start, new_stop))\n",
    "        else:\n",
    "            slices_fixed.append(s)\n",
    "    \n",
    "    return slices_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = indices_to_slices_fixed(sub_indices_in_full_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "logits = torch.randn(\n",
    "    batch_size, 4, 336\n",
    ")\n",
    "\n",
    "left_flank = X_batch[2,:, :10328].unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "right_flank = X_batch[2,:, :-10664].unsqueeze(0).repeat(batch_size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_flank.shape, right_flank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10328 + 22104 + 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StraightThroughParameters(\n",
       "  (norm): InstanceNorm1d(336, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = boda.generator.StraightThroughParameters(\n",
    "    data=logits, left_flank=left_flank, right_flank=right_flank, \n",
    "    token_dim=2\n",
    ")\n",
    "params.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy = boda.generator.MinGapEnergy(model, target_feature=21, target_alpha=-1, a_min=-2., a_max=6.)\n",
    "# energy = boda.generator.MinGapEnergy(model, target_feature=slice(96,980), target_alpha=-1, a_min=-2., a_max=6.)\n",
    "energy = boda.generator.MinGapEnergy(model, target_feature=slices, target_alpha=-1, a_min=-2., a_max=6.)\n",
    "\n",
    "#Higher or Lower?:\n",
    "# - If you want the target feature to be higher in the energy calculation (i.e., the energy should be lower when the target feature is higher), \n",
    "# then you’ll use a positive target_alpha.\n",
    "# - If you want the target feature to be lower (i.e., the energy should be lower when the target feature is lower), \n",
    "# then you’ll use a negative target_alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = boda.generator.AdaLead(energy, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting at most 1 sequences per batch\n",
      "At least 2 batches are needed to propose 2 sequences\n",
      "Make sure max_attempts >= 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1 (0/2 proposals generated ):   0%|          | 0/30 [00:00<?, ?it/s]/home1/smaruj/miniconda3/envs/pytorch_cuda11.8/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:115: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(\n",
      "Penalty not implemented\n",
      "Batch 1 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.97it/s, Batch mean fitness=-337]\n",
      "Batch 2 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.85it/s, Batch mean fitness=-337]\n",
      "Batch 3 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.15it/s, Batch mean fitness=-337]\n",
      "Batch 4 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.78it/s, Batch mean fitness=-337]\n",
      "Batch 5 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.20it/s, Batch mean fitness=-337]\n",
      "Batch 6 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.90it/s, Batch mean fitness=-337]\n",
      "Batch 7 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.05it/s, Batch mean fitness=-337]\n",
      "Batch 8 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.19it/s, Batch mean fitness=-337]\n",
      "Batch 9 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.18it/s, Batch mean fitness=-337]\n",
      "Batch 10 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.02it/s, Batch mean fitness=-337]\n",
      "Batch 11 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.89it/s, Batch mean fitness=-337]\n",
      "Batch 12 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.04it/s, Batch mean fitness=-337]\n",
      "Batch 13 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.20it/s, Batch mean fitness=-337]\n",
      "Batch 14 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.13it/s, Batch mean fitness=-337]\n",
      "Batch 15 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.09it/s, Batch mean fitness=-337]\n",
      "Batch 16 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.18it/s, Batch mean fitness=-337]\n",
      "Batch 17 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.90it/s, Batch mean fitness=-337]\n",
      "Batch 18 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.97it/s, Batch mean fitness=-337]\n",
      "Batch 19 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.87it/s, Batch mean fitness=-337]\n",
      "Batch 20 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.02it/s, Batch mean fitness=-337]\n",
      "Batch 21 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.83it/s, Batch mean fitness=-337]\n",
      "Batch 22 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.99it/s, Batch mean fitness=-337]\n",
      "Batch 23 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.22it/s, Batch mean fitness=-337]\n",
      "Batch 24 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.78it/s, Batch mean fitness=-337]\n",
      "Batch 25 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.93it/s, Batch mean fitness=-337]\n",
      "Batch 26 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.14it/s, Batch mean fitness=-337]\n",
      "Batch 27 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.87it/s, Batch mean fitness=-337]\n",
      "Batch 28 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.14it/s, Batch mean fitness=-337]\n",
      "Batch 29 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.06it/s, Batch mean fitness=-337]\n",
      "Batch 30 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.13it/s, Batch mean fitness=-337]\n",
      "Batch 31 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.78it/s, Batch mean fitness=-337]\n",
      "Batch 32 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.96it/s, Batch mean fitness=-337]\n",
      "Batch 33 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.04it/s, Batch mean fitness=-337]\n",
      "Batch 34 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.20it/s, Batch mean fitness=-337]\n",
      "Batch 35 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.00it/s, Batch mean fitness=-337]\n",
      "Batch 36 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.89it/s, Batch mean fitness=-337]\n",
      "Batch 37 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.09it/s, Batch mean fitness=-337]\n",
      "Batch 38 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.10it/s, Batch mean fitness=-337]\n",
      "Batch 39 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.08it/s, Batch mean fitness=-337]\n",
      "Batch 40 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.19it/s, Batch mean fitness=-337]\n",
      "Batch 41 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.94it/s, Batch mean fitness=-337]\n",
      "Batch 42 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.92it/s, Batch mean fitness=-337]\n",
      "Batch 43 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.05it/s, Batch mean fitness=-337]\n",
      "Batch 44 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.63it/s, Batch mean fitness=-337]\n",
      "Batch 45 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.96it/s, Batch mean fitness=-337]\n",
      "Batch 46 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.02it/s, Batch mean fitness=-337]\n",
      "Batch 47 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.02it/s, Batch mean fitness=-337]\n",
      "Batch 48 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.28it/s, Batch mean fitness=-337]\n",
      "Batch 49 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.18it/s, Batch mean fitness=-337]\n",
      "Batch 50 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.26it/s, Batch mean fitness=-337]\n",
      "Batch 51 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.29it/s, Batch mean fitness=-337]\n",
      "Batch 52 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.08it/s, Batch mean fitness=-337]\n",
      "Batch 53 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.88it/s, Batch mean fitness=-337]\n",
      "Batch 54 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.87it/s, Batch mean fitness=-337]\n",
      "Batch 55 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.94it/s, Batch mean fitness=-337]\n",
      "Batch 56 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.82it/s, Batch mean fitness=-337]\n",
      "Batch 57 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.16it/s, Batch mean fitness=-337]\n",
      "Batch 58 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.07it/s, Batch mean fitness=-337]\n",
      "Batch 59 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.11it/s, Batch mean fitness=-337]\n",
      "Batch 60 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.90it/s, Batch mean fitness=-337]\n",
      "Batch 61 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.87it/s, Batch mean fitness=-337]\n",
      "Batch 62 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.93it/s, Batch mean fitness=-337]\n",
      "Batch 63 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.27it/s, Batch mean fitness=-337]\n",
      "Batch 64 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.93it/s, Batch mean fitness=-337]\n",
      "Batch 65 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.78it/s, Batch mean fitness=-337]\n",
      "Batch 66 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.05it/s, Batch mean fitness=-337]\n",
      "Batch 67 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.94it/s, Batch mean fitness=-337]\n",
      "Batch 68 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.05it/s, Batch mean fitness=-337]\n",
      "Batch 69 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.82it/s, Batch mean fitness=-337]\n",
      "Batch 70 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.01it/s, Batch mean fitness=-337]\n",
      "Batch 71 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.28it/s, Batch mean fitness=-337]\n",
      "Batch 72 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.99it/s, Batch mean fitness=-337]\n",
      "Batch 73 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.96it/s, Batch mean fitness=-337]\n",
      "Batch 74 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.88it/s, Batch mean fitness=-337]\n",
      "Batch 75 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.84it/s, Batch mean fitness=-337]\n",
      "Batch 76 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.05it/s, Batch mean fitness=-337]\n",
      "Batch 77 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.81it/s, Batch mean fitness=-337]\n",
      "Batch 78 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.16it/s, Batch mean fitness=-337]\n",
      "Batch 79 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.89it/s, Batch mean fitness=-337]\n",
      "Batch 80 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.08it/s, Batch mean fitness=-337]\n",
      "Batch 81 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.15it/s, Batch mean fitness=-337]\n",
      "Batch 82 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.03it/s, Batch mean fitness=-337]\n",
      "Batch 83 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.87it/s, Batch mean fitness=-337]\n",
      "Batch 84 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.00it/s, Batch mean fitness=-337]\n",
      "Batch 85 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.17it/s, Batch mean fitness=-337]\n",
      "Batch 86 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.98it/s, Batch mean fitness=-337]\n",
      "Batch 87 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.71it/s, Batch mean fitness=-337]\n",
      "Batch 88 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.12it/s, Batch mean fitness=-337]\n",
      "Batch 89 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  6.00it/s, Batch mean fitness=-337]\n",
      "Batch 90 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.03it/s, Batch mean fitness=-337]\n",
      "Batch 91 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.03it/s, Batch mean fitness=-337]\n",
      "Batch 92 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.84it/s, Batch mean fitness=-337]\n",
      "Batch 93 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.02it/s, Batch mean fitness=-337]\n",
      "Batch 94 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.14it/s, Batch mean fitness=-337]\n",
      "Batch 95 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.87it/s, Batch mean fitness=-337]\n",
      "Batch 96 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.94it/s, Batch mean fitness=-337]\n",
      "Batch 97 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.85it/s, Batch mean fitness=-337]\n",
      "Batch 98 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.90it/s, Batch mean fitness=-337]\n",
      "Batch 99 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.85it/s, Batch mean fitness=-337]\n",
      "Batch 100 (0/2 proposals generated ): 100%|██████████| 30/30 [00:04<00:00,  6.11it/s, Batch mean fitness=-337]\n",
      "Batch 101 (0/2 proposals generated ): 100%|██████████| 30/30 [00:05<00:00,  5.84it/s, Batch mean fitness=-337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_proposals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menergy_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m336.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecomb_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_top_seqs_per_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_queries_per_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/boda2/boda/generator/AdaLead.py:228\u001b[0m, in \u001b[0;36mAdaLead.generate\u001b[0;34m(self, n_proposals, energy_threshold, n_steps, n_top_seqs_per_batch, mu, recomb_rate, threshold, rho, model_queries_per_batch, max_attempts)\u001b[0m\n\u001b[1;32m    225\u001b[0m     attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n_top_seqs_per_batch\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m--> 228\u001b[0m proposals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdna2tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproposal\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproposal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_proposals\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m energies \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(energies[:n_proposals])\n\u001b[1;32m    230\u001b[0m acceptance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(acceptance)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "results = AL.generate(\n",
    "    n_proposals=2, n_steps=30, rho=2, threshold=0.05, mu=1, \n",
    "    energy_threshold=336.7, recomb_rate=0.1, n_top_seqs_per_batch=1, \n",
    "    model_queries_per_batch=10*batch_size, max_attempts=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in results.keys():\n",
    "    print(k)\n",
    "    print(f\"\\t{results[k].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"proposals\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_proposals = results[\"proposals\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_seq = X_batch[1,:,:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seq = og_seq.clone()\n",
    "mod_seq[:, 10328:10664] = squeezed_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(og_seq != mod_seq).sum() // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_seq_dim = mod_seq.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions_new = model(mod_seq_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(from_upper_triu(predictions[1], matrix_len=64, num_diags=2), vmin=-0.6, vmax=0.6, palette=\"RdBu_r\", width=5, height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(from_upper_triu(predictions_new, matrix_len=64, num_diags=2), vmin=-0.6, vmax=0.6, palette=\"RdBu_r\", width=5, height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_region = (0, 21, 21, 38)\n",
    "plot_map(from_upper_triu(predictions_new, matrix_len=64, num_diags=2), highlight_region=highlight_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_map(from_upper_triu(predictions[1], matrix_len=64, num_diags=2), vmin=-0.6, vmax=0.6, palette=\"RdBu_r\", width=5, height=5, highlight_region=highlight_region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
